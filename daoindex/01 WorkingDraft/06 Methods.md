
# Notes
## Data Collection 

- Purposeful Sampling Strategy
	- Why the 10 DAOs
	- Generalizability 
- How we conducted the assessment 
## Data Analysis

- Assessment Results Analysis
- Instrument Validity Checks
	- Validity checks
		- External: question independence
	- Reliability checks
		- Internal check: Inter-rater reliability

# Prose

## Data Collection

We conducted eleven assessments with the DAO Index Version 0.9. We generated our responses by completing the questionnaire ourselves for each DAO evaluated (i.e., conducting a draft assessment).

We based our responses on publicly available information provided directly (or primary source) by the DAO evaluated, or indirectly by a third party source (secondary source).

You can find our data sources in the table below.

[table]

We selected eleven DAOs of varying ownership and governance structures, missions, industry verticals, etc., to see the universality of the questionnaire (i.e., how often the questions were inapplicable to a particular organization).

You can find a table of the DAO characteristics from DeepDAO and [name of other data sources] below.

[table]

## Data Analysis

### Assessment Results
We conducted the following analyses on the draft assessments (refer to Analysis notebook; results of analysis notebook should be included in Findings section):

1. examined the correlation of responses (for question independence?)
2. created radar charts for each DAO based on their scores per principle
3. created a bar chart of each DAO's overall score
3. created a bar chart of each DAO's scores per principle
5. created a scores table for overall scores and scores per principle for all DAOs assessed
6. count of questions where no information could be found to answer the question
7. count of questions inapplicable to a DAO
8. %%?determined areas of improvement for the questionnaire?%%

### Instrument Analysis

We conducted the following analyses on the questionnaire:

1. Inter-rater reliability
2. Question independence
 